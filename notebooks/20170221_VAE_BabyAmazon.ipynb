{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses Amazon (baby products) ratings data to predict ratings on other products.  The data is very, very sparse however (less than 0.1%) so you shouldn't really expect a good model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://github.com/ipython/ipykernel/issues/111\n",
    "# Create logger\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Create STDERR handler\n",
    "import sys\n",
    "handler = logging.StreamHandler(sys.stderr)\n",
    "# ch.setLevel(logging.DEBUG)\n",
    "\n",
    "# Create formatter and add it to the handler\n",
    "formatter = logging.Formatter('%(asctime)-15s : %(levelname)s : %(message)s') # - %(name)s %(clientip)s %(user)-8s\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "# Set STDERR handler as the only handler \n",
    "logger.handlers = [handler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n",
    "%matplotlib inline\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user          object\n",
      "item          object\n",
      "rating       float64\n",
      "timestamp      int64\n",
      "dtype: object\n",
      "Index(['user', 'item', 'rating', 'timestamp'], dtype='object')\n",
      "(915446, 4)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "datasets_path = '/home/fred/data'\n",
    "small_ratings_file = os.path.join(datasets_path, 'amazon', 'ratings_Baby.csv')\n",
    "df = pd.read_csv(small_ratings_file, sep=',', header=None, names=['user', 'item', 'rating', 'timestamp'])\n",
    "print('{}\\n{}\\n{}'.format(df.dtypes, df.columns, df.shape)) # 915,446 total ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-24 07:57:23,557 : INFO : tf_amazon imported\n",
      "2017-02-24 07:57:23,570 : INFO : Loading train.py\n"
     ]
    }
   ],
   "source": [
    "from tf_amazon import sparse_pivot\n",
    "from tf_amazon import vae\n",
    "from tf_amazon import dataset\n",
    "from tf_amazon import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58940\n",
      "shape=(58940, 1332); n_nonzero=[50000, 20000, 0]; pct_nonzero=0.064%\n"
     ]
    }
   ],
   "source": [
    "reload(sparse_pivot)\n",
    "\n",
    "# including both training and test data in the same matrix so that all users and\n",
    "# items are accounted for in the resulting DataSet\n",
    "n_training = 50000 # training takes 6 minutes for 30 epochs with 50k and 20k\n",
    "n_validation = 20000\n",
    "n_test = 0\n",
    "trmat, vamat, temat = sparse_pivot.f(df[0 : n_training + n_validation + n_test],\n",
    "                                     'user', 'item', 'rating', n_validation, n_test)\n",
    "\n",
    "# scale down to [0,1], though note that 0 indicates missing value in csr_matrix, this is what was causing\n",
    "# the cost to go to NaN at times, self.x_reconstr_mean would end up with a value of 1.0 which would cause\n",
    "# tf.log(1e-10 + 1 - self.x_reconstr_mean) to be -inf\n",
    "trmat = trmat * 0.2\n",
    "vamat = vamat * 0.2\n",
    "temat = temat * 0.2\n",
    "\n",
    "# number of *unique* users and items\n",
    "n_users = trmat.shape[0]\n",
    "n_items = trmat.shape[1] # scipy.sparse.csr_matrix\n",
    "print(n_users) # TODO: shouldn't there be fewer given overlap (or perhaps no overlap in first 50?)\n",
    "pct_nonzero = n_training * 100 / trmat.shape[0] / trmat.shape[1]\n",
    "print('shape={}; n_nonzero=[{}, {}, {}]; pct_nonzero={:.3f}%'.format(trmat.shape, len(trmat.nonzero()[0]),\n",
    "                                                len(vamat.nonzero()[0]), len(temat.nonzero()[0]), pct_nonzero))\n",
    "#print(trmat.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO:\n",
    "1. need to sample evenly from the 5 recommendation levels\n",
    "  * or just weight predictions in the loss function inversely proportional to their occurrence probability\n",
    "2. probably also need to exclude users with only 1 rating during training as:\n",
    "  * they don't contain any relevant useful information in the way of the relationship between ratings of a single user\n",
    "  * and, as such, they bias the computed error upwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-24 07:58:56,425 : INFO : Loading train.py\n",
      "/home/fred/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:91: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size = 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-24 07:59:11,579 : INFO : Epoch: 001 cost=0.672 vacost=0.791 rmse=0.2662 varmse=0.4302\n",
      "2017-02-24 07:59:11,632 : INFO :                     [0.475, 0.326, nan, 0.132, 0.225] avg=nan stdev=nan\n",
      "2017-02-24 07:59:24,540 : INFO : Epoch: 002 cost=0.399 vacost=0.783 rmse=0.2552 varmse=0.4264\n",
      "2017-02-24 07:59:24,540 : INFO :                     [0.487, 0.340, nan, 0.118, 0.200] avg=nan stdev=nan\n",
      "2017-02-24 07:59:37,249 : INFO : Epoch: 003 cost=0.397 vacost=0.776 rmse=0.2541 varmse=0.4227\n",
      "2017-02-24 07:59:37,250 : INFO :                     [0.488, 0.338, nan, 0.117, 0.198] avg=nan stdev=nan\n",
      "2017-02-24 07:59:50,236 : INFO : Epoch: 004 cost=0.397 vacost=0.771 rmse=0.2537 varmse=0.4201\n",
      "2017-02-24 07:59:50,237 : INFO :                     [0.486, 0.337, 0.200, 0.117, 0.197] avg=0.267 stdev=0.130\n",
      "2017-02-24 08:00:03,223 : INFO : Epoch: 005 cost=0.396 vacost=0.766 rmse=0.2535 varmse=0.4177\n",
      "2017-02-24 08:00:03,223 : INFO :                     [0.487, 0.338, 0.201, 0.115, 0.197] avg=0.268 stdev=0.131\n",
      "2017-02-24 08:00:15,789 : INFO : Epoch: 006 cost=0.396 vacost=0.765 rmse=0.2533 varmse=0.4170\n",
      "2017-02-24 08:00:15,790 : INFO :                     [0.490, nan, 0.200, 0.116, 0.196] avg=nan stdev=nan\n",
      "2017-02-24 08:01:16,491 : INFO : Epoch: 011 cost=0.394 vacost=0.760 rmse=0.2527 varmse=0.4141\n",
      "2017-02-24 08:01:16,491 : INFO :                     [nan, nan, nan, 0.113, 0.194] avg=nan stdev=nan\n",
      "2017-02-24 08:02:16,791 : INFO : Epoch: 016 cost=0.394 vacost=0.756 rmse=0.2525 varmse=0.4119\n",
      "2017-02-24 08:02:16,792 : INFO :                     [0.487, 0.337, nan, 0.115, 0.195] avg=nan stdev=nan\n",
      "2017-02-24 08:03:16,646 : INFO : Epoch: 021 cost=0.394 vacost=0.754 rmse=0.2519 varmse=0.4113\n",
      "2017-02-24 08:03:16,647 : INFO :                     [0.486, nan, nan, 0.115, 0.194] avg=nan stdev=nan\n",
      "2017-02-24 08:04:17,627 : INFO : Epoch: 026 cost=0.394 vacost=0.753 rmse=0.2523 varmse=0.4105\n",
      "2017-02-24 08:04:17,627 : INFO :                     [0.485, 0.339, 0.199, 0.114, 0.194] avg=0.266 stdev=0.131\n",
      "2017-02-24 08:05:07,752 : INFO : Epoch: 030 cost=0.393 vacost=0.751 rmse=0.2515 varmse=0.4098\n",
      "2017-02-24 08:05:07,752 : INFO :                     [0.488, nan, 0.200, 0.114, 0.193] avg=nan stdev=nan\n",
      "2017-02-24 08:05:07,753 : INFO : Training complete\n"
     ]
    }
   ],
   "source": [
    "reload(vae)\n",
    "reload(dataset)\n",
    "reload(train)\n",
    "\n",
    "trdata = dataset.DataSet(trmat)\n",
    "vadata = dataset.DataSet(vamat)\n",
    "\n",
    "netarch = dict(\n",
    "         n_input=trmat.shape[1], # number of items (e.g. 258 items vs. 9617 users)\n",
    "         n_hidden_recog_1=60, # 1st layer encoder neurons\n",
    "         n_hidden_recog_2=40, # 2nd layer encoder neurons\n",
    "         n_z=20,              # dimensionality of latent space\n",
    "         n_hidden_gener_1=40, # 1st layer decoder neurons\n",
    "         n_hidden_gener_2=60) # 2nd layer decoder neurons\n",
    "\n",
    "untrained_vae = vae.VariationalAutoencoder(netarch,\n",
    "                                           min_rating=0.2,\n",
    "                                           use_rmse=False,\n",
    "                                           rdist=None)\n",
    "\n",
    "batch_size = int(min(100, n_users/10))\n",
    "print('batch_size = {}'.format(batch_size))\n",
    "trained_vae = train.train(untrained_vae, trdata, vadata, display_step=5, training_epochs=30, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: How really useful are ratings anyway?  The original ratings idea was based around sentiment, that it was a more fundamental building block than a Tweet.  But how much does someone really use their ratings on Netflix--occasionally at best.  On the other hand search is very useful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poly: 0.2051 x + 0.6209; uniqpoly: 0.1326 x + 0.6417\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4QAAAFLCAYAAACOb0JzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzs3XucXVV5+P/Pk4QQksBwSTITTBRyEbAiIVFuQao/VIrI\nxWCLg2gE1C9oawmttbRfLkoRtUB+2oqJiAJVx6KdFgULFmurQEAkhEoFAglB0ZwJARKYXGBI1veP\nfYY5MzkzmXMycy5zPu/X67zO7HXW3vuZTcjOc9ba64mUEpIkSZKkxjOq2gFIkiRJkqrDhFCSJEmS\nGpQJoSRJkiQ1KBNCSZIkSWpQJoSSJEmS1KBMCCVJkiSpQZkQSpIkSVKDMiGUJEmSpAZlQihJkiRJ\nDcqEUNKAIuKyiNhe7TgkSZI09EwIVZMiYmFEbC94dUXE0xHxzYjYv9rxDaWI2CMiLo2I42o0hgSY\nEEqShlSRe33ha1tEHFHtGKVGMKbaAUgDSMDFwBpgHHAUcDYwPyLemFJ6uYqxDaXxwKVkv+/PajCG\ny4ErKx6RJKkRFN7r+3qisqFIjcmEULXu9pTS8vzP34iIZ4G/Ak4Bvl+9sIZUlNQ5YnxKaXOlYkgp\nbQdGSvItSao9hff6nYqI0cColFJXkc92B15OKaVygxmKY0j1xCmjqjc/J0teZhY2RsSJEfGziOiM\niBci4taIeEPfnSPioIi4OSLWRcTmiHg0Iv6uT5/DI+LfI2JjRLwYEXdGxJF9+nRPczkmIq7JH68z\nItojYr8+fd8cEXdExDP5c66OiOvzn70OWEf2DellBVNlLsl/fkM+hhkR8aOIeAH4Vv6zNRHxjSK/\n439FxH/2ads9/yzgYxGxJSJ+HxH/EhEHDiKGHZ4hjIjREXFxRDwREVsj4smIuCIixvbptyYifhAR\n8yPivvy5V0XEB/v0G5Ofsroy32d9RPw8Io7v+/tJkhpHRLwuf0+6MCL+PCKeALYCh0TEH+Y/OyMi\n/i4ingY2AXvm9z0wIr4XEc9GxKaIWBYR7+5z/H6P4b1JjcIRQtWbA/Pvz3c35JOLG4DbyUYPxwPn\nAz+PiMNTSr/J93sTWUL5ErAUeIossXwP8H/zfd5ANmVyI/B54BXg/wD/FRHHpZTu7xPPPwDPAZcB\nBwCLgH8EWvPHmwzcQZZwXQlsyPdbkN//GeA8YAnQnn8B/E/+PZH9f3pHPva/ADYXfFZMr/aIGAXc\nBrwdaAP+f7Kb5TuBNwJ3DiKGvue6HvgQcDNwFXAkcBFwMHB6n1hmA9/L73MDcA7wzYj4ZUrpkXy/\nzwB/DXwNuB/YC3gzMBf4ST+/pyRpZGjq+2UqkFJKzxVsnwPsTnb/fons3rtP/rOL821/n+/zckRM\nAZaRPXLypXz/hcAPIuL0lNItfc5XeIyxZDNjvDepMaSUfPmquRfZX9rbyJKY/YDXkCUaHWTf3O2f\n7zeB7C/5r/bZfzJZ0rikoO2/yRKy1wxw3n8FtgCvK2hrIUsQf9onvu1k01wK97+a7CayZ3771Pzv\ncfgA59wvf6xLinz2zfz+f1fksyeBbxRp/ynwnwXbZ+eP/8kyY7gU2Faw/aZ83yV9+n0xH+sf9olx\nG3BMQduk/DX+YkHbg8APqv3nzpcvX758Ve5VcC8t9tqc7/O6/PbzwL599v/D/GePA2P7fLY4f/85\nuqBtArAKWDXIY3hv8tUQL6eMqpYF2TdwzwC/JRtl6gROSSn9Pt/nnUAT8N2I2K/7RTYydR9ZQklE\nTALeClyfUvpd0ZNlI2nvBP41pfRUd3tKKQd8Bzg2IiYW7JLIvjUs9HNgNNkNDLIENIBTImJXRuSX\n7MK+C8iu4T/uwjEKvZvsd1/cp/1qst/1pD7tv04p3dO9kVJaDzwGzCjoswH4g4iYNUQxSpLqQyKb\n1fOOPq8T+/T7fuo9YljohrTjQnMnAr9IKS179UQpbSK7bx9Q5LGSYsfw3qSG4JRR1bIEfJzsW7sm\nsukix9F7gZPZZEnIT/vZf2P+5+7k438HON9ksummK4t89gjZM7fT8z93+22fft1TWfcBSCn9d0R8\nH7gEWBQR/wX8G/CdIjee/rySUnp6kH2LmQk8lrLFYYZC97e1vVZ/Syl1RMQGepLhbr8pcozn6Znq\nA9n1+TdgZUQ8TDb9959SSr8aopglSbXr/rTzRWXWlPjZ64B7i7Q/UvD5r3dyDO9NagiOEKrW3Z9S\n+s+U0r+STb/8X+A7ETE+//kossTvA+z47eI7gdOGOb5t/bS/umpnSulPgKPJnjfcH/gG8MuC32Fn\nXuqnvb9nCEcP8ri7arCrrw3mGv2cLHE9G/gVcC6wPCLO2aUIJUkjxZYyPyv7+N6b1ChMCFU38iNc\nF5E9T/in+eZVZInFM/nEse+ru6be6vz7Gwc4xTNkC7YcVOSzQ8hGxfqOCA429l+klC5OKR1Blry+\nEXh/98flHJNslG3vIu19R+hWAQdFtkx3vyGWcN6nyP7umF3YmH+Af+/85yVLKW1IKd2YUvoA2Ujs\n/5At1iNJUqmeov/7effnO+W9SY3AhFB1JaX038AvgAvyJQ7uAF4A/qbYM3r5Zwe7n1v7GXBOREzv\n59jbgR8Dp0bEawuO0Uy2aujPU0qdpcQbEcUStofy77vn37tXDS3WdyCrgKMKf++IeA/ZDavQv5BN\nh/1T+ldKDD8iS8Iv6NP+F2SJ5W2DOEYvEbFv4XbK6iw+Qc81kiSpFD8CjoiCslERMQH4GPBkSunX\n/e7Z0997kxqCzxCqlvVXLP3vyRaY+XBK6WsRcT5wE9k0ju+SjfS9lmxxk7uAT+b3+yTZoi/LI+Jr\nZCtgHgi8O6V0eL7P/yWbbnp3RFxLNt3xY2RLUP/VIOMrbF8YER8nW710FVm5h4+SPdv4I4CU0taI\n+DVwRkQ8TrZq6sMppYGedwT4OvA+4I6IuJlsWstZ9Hm2L39tPgRck78x/hyYCBwPfCWl9MNSYkgp\n/U9E3Ah8LCL2IVu99cj8OdrzSXupfp1/vvKB/Lnfkv/dvlzGsSRJ9SOAd0fEIUU+u5vyZ9F8nuzL\n3Nsj4stk95YPk82iWTDAfoW8N6khmBCqlvV3E2gnS67+MiKuSym1RcTvyGoF/SXZN3e/I0t8vvnq\nwbJE5ijgcrK6e+PIpoz8c0GfX0fEW8lqBv412Sj6vcCZKaVfDjK+wvb/JruBnAE0kyWC9+WPVzhd\n5VyyZwyvIUs+P0PPAjhFz5NS+nFEXAhcSLbi5/1kSfA1hfuklLZHxInA3wJnkt0In81fn8IH40uJ\n4Vyy/wYfJntOMwdcAXy2yLUYzHX6EnAK2XOfu5P9d/kbshqHkqSRK5Hdb4o5m+w+Oth7SU9jSusi\n4mjgC2QzZMaRTfd8T0rp9sEcA+9NahCRUrlfvEiSJEmS6lnJzxBGxFsj4gcR8buI2B4Rpwxin7dF\nxAMRsTUiVkbEwvLClSRJkiQNlXIWlZkArCCrD7fT4cWIOAC4lazA+GFkw+9fj4h3lnFuSZIkSdIQ\n2aUpoxGxHTgtpfSDAfp8ATgxpfSmgrY2oCml9O6yTy5JkiRJ2iWVKDtxFHBnn7Y7yAp1S5IkSZKq\npBKrjLYAHX3aOoC9ImL3lNJLfXeIiP2AE4A1wNZhj1CSVIvGAQcAd6SUnq1yLHXDe6gkiRLuobVa\nduIE4NvVDkKSVBM+AHyn2kHUEe+hkqRuO72HViIhzJHVXyvUDLxQbHQwbw3At771LQ45pFid0upZ\ntGgRixcvrnYYdcfrVjqvWXm8boOweTNcdRXccgv/xXF8mpd5ha9w2GHwjW9UO7gejzzyCGeddRbk\n7wkatDXgPXQk8bqVzmtWHq9b6Wr1mpVyD61EQrgMOLFP27vy7f3ZCnDIIYcwd+7c4YqrLE1NTTUX\nUz3wupXOa1Yer9tOLFsGH/4w5HK8cPV1fPJfzmXsilM58vC5tLfDlCnVDrAopz2WxnvoCON1K53X\nrDxet9LVwTXb6T20nDqEEyLisIiYk2+akd+env/8yoi4sWCXJfk+X4iIgyLi48D7gGtKPbckqUxd\nXXDJJXDssTB5MqxYwV4XfoS77g6OPx7uuqtmk0FJkjSMyhkhfDPwU7IahAm4Ot9+I3AO2SIy07s7\np5TWRMRJwGLgk8DTwLkppb4rj0qShsPKlXDWWbB8OVx2GVx0EYyp1UfIJUlSJZX8L4KU0n8zwMhi\nSunsIm0/A+aVei5J0i5ICZYuhQsvhGnT4J574Igjqh2VJEmqIZWoQziitLa2VjuEuuR1K53XrDxe\nt7xcDk4+Gc4/HxYuhAcf7DcZ9JqpUvyzVh6vW+m8ZuXxupVuJFyzSClVO4YdRMRc4IEHHnig1h/S\nlKTac8st8JGPwKhR2bKhJ51U7YjKsnz5cubNmwcwL6W0vNrx1AvvoZKkUu6hjhBK0kjR2Zklgqed\nBsccA7/6Vd0mg5IkqTJcVUCSRoJly+CDH8ymil53HZx7LkRUOypJklTjHCGUpHpWpJwEH/mIyaAk\nSRoURwglqV5ZTkKSJO0iRwglqd6kBEuWwJw5sGFDVk7i4otNBiVJUslMCCWpnpRQTkKSJGln/DpZ\nkupFYTmJW291BVFJkrTLHCGUpFpnOQlJkjRMHCGUpFpmOQlJkjSMHCGUpFpkOQmp4XV0ZH8FzJyZ\nva9bV+2IJI1EjhBKUq2xnIQk4PTT4e67s59Xr4YFC+Cuu6obk6SRxxFCSaoVlpOQVGDt2oG3JWko\nmBBKUi2oQjkJp6NJtW3q1IG3JWko+LWzJFVblcpJOB1Nqm3t7dn/l2vXZslge3u1I5I0EjlCKEnV\nUuVyEk5Hq46I+EREPBkRWyLi3oh4yyD3mx8RXRGxfLhjVG2YMiX7kmbVqux9ypRqRyRpJDIhlKRq\nWLYse1bwu9/Nykn8279V/F97TkervIg4A7gauBQ4HHgIuCMiJu1kvybgRuDOYQ9SktRQTAglqZJq\nqJxEezvMnw8zZmTvTkeriEXA0pTSTSmlR4HzgM3AOTvZbwnwbeDeYY5PktRgfIZQkiqlxspJdE9H\nU2VExG7APOBz3W0ppRQRdwJHD7Df2cCBwAeAi4c7TklSYzEhlKThlhIsXQoXXgjTpmXlJIZ5BVHV\npEnAaKCjT3sHcFCxHSJiNlkCeWxKaXtUYSRZkjSymRBK0nDK5bIpobfdBuedB1ddBRMmVDsqICs7\ncfrpvVcwdNGK2hERo8imiV6aUlrV3TzY/RctWkRTU1OvttbWVlpbW4cuSElS1bW1tdHW1tarbePG\njYPe34RQkoZLlcpJDJZlJypuPbANaO7T3gzkivTfE3gzMCcivpJvGwVERLwMvCul9F/9nWzx4sXM\nnTt3l4OWJNW2Yl/2LV++nHnz5g1qfxeVkaShVlhOYv58ePjhmksGwbITlZZS6gIeAI7vbotsDujx\nwD1FdnkBeCMwBzgs/1oCPJr/+b5hDlmS1AAcIZSkobRsGXzwg9lU0euug3PPrcoKooMxdWo2Mli4\nrWF3DXBDRDwA/IJs1dHxwA0AEXElsH9KaWFKKQG/Ltw5ItYBW1NKj1Q0aknSiGVCKElDoasLLr8c\nrrgiWzDm9tth1qxqRzWg9vZsmmjhM4QaXimlm/M1Bz9LNlV0BXBCSumZfJcWYHq14pMkNR4TQkna\nVTVWTmKwLDtRHSmla4Fr+/ns7J3s+xngM8MRlySpMfkMoSSVKyVYsgTmzIENG7JyEhdfXBfJoCRJ\nEpgQSlJ5cjk4+WQ4/3xYuBAefNDagpIkqe74NbYklarGy0lIkiQNliOEkjRYdVJOQpIkabAcIZSk\nwaijchKSJEmD5QihJA2kqwsuuQSOPRYmT4YVK7JRQpNBSZI0AjhCKEn9qdNyEpIkSYPlCKEk9WU5\nCUmS1CBMCCWpkOUkJElSAzEhlKRut9wChx4K99+flZP46ldhwoRqRzVsOjqyRyNnzsze162rdkSS\nJKnSTAglqUHLSZx+Otx9N6xenb0vWFDtiCRJUqWZEGpYOQKhmrdsWfas4He/m5WT+Nd/zVYTbQBr\n1w68LUmSRj4TQg0rRyBUsywnwdSpA29LkqSRzyXzNKwcgVBNspwEkA2KnnIK/P73MGMGtLdXOyJJ\nklRpjfcvIFXU1KnZ6GDhtlQ1KcHSpXDhhTBtWlZOYoSvIPryy/Dkk/D44/DEE9l79+s3v4Ht27N+\nd90FU6ZUN1ZJvXV0ZDNt1q7N7p/t7f5/KmnomRBqWLW3Z9NEC29mUlXkctmU0Ntug/POg6uuGjEr\niHZ1wZo1vZO97gRwzZqepG/cOJg1C2bPhj/5k56fZ8+G/fev5m8gqZjuxy4g+3J1wYLsyxtJGkpl\nJYQR8QngL4EW4CHgz1JK9w/Q/wPAp4DZwEbg34FPpZSeK+f8qh9TpnjzUg245ZYsGRw1KisnUYcr\niL7ySu+kr3C0b80a2LYt67f77j2J3oIFPQlfd9I3yifHpbrhYxeSKqHkhDAizgCuBj4G/AJYBNwR\nEa9PKa0v0n8+cCPw58CtwGuApcDXgPeVH7ok7URnJ1xwAVx/PZx6araKaA2vIPrKK/DUU8Wnd65Z\nk30OMHZstnLv7NlZpYzuhG/WrGwmrEmfNDL42IWkSihnhHARsDSldBNARJwHnAScA3yxSP+jgCdT\nSl/Jbz8VEUuBvyrj3JI0OMuWwQc/mE0Vve46OPfcmlhBdNu2LOnrm/A98UT2rF9XV9Zv7NhsoZfZ\ns7OFXwqnd06bBqNHV/f3kDT8fOxCUiWUlBBGxG7APOBz3W0ppRQRdwJH97PbMuCKiDgxpfTvEdEM\n/DFwW5kxS1L/urrg8svhiiuyBWNuvz3Lpipo2zb47W93TPgefzz7tr876dttt56k793v7j29c/p0\nkz6p0fnYhaRKKHWEcBIwGujo094BHFRsh5TSPRFxFvDPETEuf84fAH9a4rklaWAVLCexfXvvpK9w\nxG/16mx1T8hOP2NGlpP+0R/1nt752tc2ZLULSZJUQ4b9nyIR8QbgS8BlwI+BqcBVZM8RfmSgfRct\nWkRTU1OvttbWVlpbW4clVkl1apjKSWzfDk8/veP0zu6k76WXsn6jR8OBB2aJ3rve1ZPwzZ4Nr3ud\nSd9gtLW10dbW1qtt48aNVYpGkqTGUeo/U9YD24DmPu3NQK6fff4auDuldE1+++GI+Djw84j425RS\n39HGVy1evJi5c+eWGKKkhrKL5SS2b88Ksxeb3rlqFWzdmvUbPRoOOCBL8t7xjt7P9L3uddn0T5Wv\n2Jd9y5cvZ968eVWKSJKkxlBSQphS6oqIB4DjyaZ9EhGR3/5yP7uNB17u07YdSED1V3iQVL8Kykk8\n/0+3cvKSk1j7ph0LOKfUO+krHPFbtQq2bMn6jRqVJX2zZsHb3gYf/WhP0nfAASZ9kiRp5ClnItM1\nwA35xLC77MR44AaAiLgS2D+ltDDf/4fA1/Krkd4B7A8sBu5LKfU3qihJ/StSTuI9p03mnnuyj1ev\nhrlz4cgjs+TviSdg8+bss1Gjsmf3Zs+G447LFh/tHu078MBsdU9JkqRGUXJCmFK6OSImAZ8lmyq6\nAjghpfRMvksLML2g/40RMRH4BNmzgxuAn5BNJZWkQUsJnr11GRPO/yBj1uf4wYnX8d0x5/L4O4P/\n+Z/efTs64IUXYP58WLiwZ6TvwAOz4u2SJEkqc1GZlNK1wLX9fHZ2kbavAF8p0l2SekkJ1q0rUqNv\nZRen//pyPtV1Bb/gCD7E7bz8v7OYPRuOOgo2bsyKt3c78kj4j/+o2q8hSZJUF1z7TlLFpQTPPFP8\nmb4nnoAXX+zpO306vG3/ldz8+7N43bblPNZ6GXt9+iJ+ddAYxo3r6bdunQWcS7Ft+zbWb15PrjNH\nx6YO3nbA2xg72vmykiQ1GhNCScMiJVi/vv+k74UXevpOm5Y9x/fmN0Nra88zfTNnJPa4qaCcxK33\ncEg/5SQs4AwpJZ7f+jwdnR3kOnOvvjo27bi9btM6tqftr+676pOrmLHPjCpGL0mSqsGEUFLZUoJn\nn90x4eveLiwjt//+WZI3dy6ccUZB0jcTxo8vcvBcDv6k/HISI0nny509ydwAyV7Hpg5e3tZ7Uefx\nu42nZWLLq69jph/Ta7t5QjMtE1t4zV6vqdJvJ0mSqsmEUNJOFUv6un/esKGn39SpWZI3Zw687309\nC7nMnFliLldQToJbb4WTThry36natr6ylY7Ojh1H7zo7yG3qvb2pa1OvfXcbtVuWzE3MkrnDmg/j\nhJknvLpdmOxNHDuRrDqQJEnSjkwIJQHw3HPFR/kefxyef76nX0tLluQdeii89729k76JE3cxiCLl\nJJg8eRcPWjmvbH+FZzY9M+BUze6fN2zd0GvfUTGKyeMnv5rMzd53NsdOP7Z3gpdP+PYZt49JniRJ\nGhImhFIDef754qN8jz+eJYTdmpuzJO8Nb8jyssKkb889hym4Zcvggx/Mpoped11WILAGkp7taTvP\nbXlup9M1c5051m9eTyL12n/fPfZ9dbRu6sSpHN5yeK+pmt2vSeMnMXrU6Cr9lpIkqVGZEEojzMaN\nxUf5Hn88m/rZbcqULMk7+GA4+eTs51mzstdee1Uw4K4uuPxyuOIKOOIIuP32LIhhlFLixZdf3HGq\nZvf2pp7tjk0dvLL9lV77Txw7sVcyd9B+BxWdrjllwhR2H2PRQ0mSVLtMCKU69MILxRO+xx/PVvbs\nNnlyllu9/vXZY3iFSV9TU/Xif9XKlXDWWbB8OVx2GVx0EYwp/6+lLV1bio7cFWvb+srWXvvuPnr3\nXlMz502dt8NUze5Eb8LYxlzcRpIkjTwmhFKNevHF/ks2rFvX02/SpJ4VO088sefnWbNg772rF/+A\nUoKlBeUk7rknGx0somtbF+s2rdtpGYVcZ44XXnqh176jYzRTJkx5NZk7ZNIhvP2At+8wXbN5YjNN\nuzf5XJ4kSWo4JoRSFb34YpbgFVvMpaOjp9+++/Y8x3fCCb2Tvn32qV78ZcnlSOeeS/zoRzz7oT9m\nxV+exe+3P0bu7v/eYbpmrjPHs1ue3eEQk8ZPejWZe23TazniNUcUfS5vv/H7MSpGVeGXlCRJqg8m\nhNIw6+yEVauKP9eXy/X022efnqTvHe/o+XnWrCwhrHUpJTZs3TDgKN7Bdz3G//2nNbxC4pwz4Ucz\nvgft3wOgafemXlMz/2DyH+wwXbNlYguTx09mt9G7Vfm3lSRJGhlMCKUhsHlz/6t3rl3b02/vvXuS\nvLe/vXfSt99+1Yt/IN1F0Xe2wmaxouh7jNmDloktHDhmMhf9Swfv+OlTPDr/IO679CN8bPpsLs4n\ne80Tmtljtz12Kc6ODjj99Ox6T50K7e3ZwjmSJEnqnwmhNEibN/eM9PWd4vn73/f0a2rqSfL+8A97\nfp49O0v6auExtZdeeal4QfT8lM3C7b5F0ceMGtNrgZU3Nb+Jd818V9EpmxPHTiTuvTdfTmI9XHcd\nB597LgcPw0U4/XS4++7s59WrYcECuOuuIT+NJEnSiGJCKBXYsiVL+oo90/f00z399tyzZ3TvrW/t\nnfRNmlSdpG9XiqIHweQJPUXRZ+07i/nT5/dK7roTvn322Gdwz+V1dcGll1asnEThSGyxbUmSJO3I\nhFDDqhan8W3dmo0gFXum7+mnswUwASZO7En6jjmm5+fZs7NyDpVI+na1KPo+4/bpldDNaZ5TtJTC\npPGTGDNqCP86GOJyEoMxdWr237VwW5IkSQMzIdSwqtY0vpde6p30FY74/fa3PUnfhAk9Sd6RR/Z+\npq+5eXiSvpQSL7z0wqCmbPZXFL1waubr93t90emaVSmKXkI5iaHW3p79+Sr88kGSJEkDMyHUsBrO\naXwvv9yT9PWd4vmb3/QkfePH9yR5Z57ZO+lraRm6pG9z1+Zeo3gDTdnsWxR97OixvZK5wqLohcle\n88RmJo6dODQBD7VcDj7yEbjtNjjvPLjqqizjrpApU3xmUPUhIj4B/CXQAjwE/FlK6f5++r4XOB+Y\nA+wO/C9wWUrpxxUKV5I0wpkQDlItTn2sB7s6je/ll+HJJ4s/0/fUU7B9e9Zvjz16nuF7//t7fp49\nOztnuUnfy9teZt2mdYNaYbNvUfRRMapXInfwpIN52+veVrSUQt0XRb/lliwZHDUKbr0VTjqp2hFJ\nNSkizgCuBj4G/AJYBNwREa9PKa0vsstxwI+Bi4ANwDnADyPiiJTSQxUKW5I0gpkQDpIrGJZnMNP4\nurpgzZreCV930rdmTU/SN25cT6L3x3+8Y9I3apD1x7dt38azW57dcapmCUXRuxO97qLofadrNk9s\nZr899mP0qNFlX7u60NkJF1wA118Pp54K112XPWApqT+LgKUppZsAIuI84CSyRO+LfTunlBb1afrb\niDgVOJlsdFGSpF1iQjhIrmBYnu5pfK+8kiV3Dzyw4xTPNWtg27as/+679yR6Cxb0Xshl//37T/pS\nSjy/ZcNOp2rmOnM8s+kZtqVtvfbfa/e9ek3PfMPkN+wwXbP7uTyLouctW5YvJ5HLEsFzz62NmhpS\njYqI3YB5wOe621JKKSLuBI4e5DEC2BN4bliClCQ1HBPCQXIFw5175ZVsGmexZ/rWrMk+hyzpmzkz\nS/xOO633M33TpvVO+ja9vIlcZ46nOnPc9+jAyV7foujjxoxj6sSpr07PPOo1RxWdrjkURdEbSlcX\nXH55xcpJaPg4Fb7iJgGjgY4+7R3AQYM8xqeACcDNQxiXJKmBmRAOkisYZrZt6z/pe/LJnqRv7FiY\nMSNL9E45pff0zsktL7F+a0evqZl3d+Zof7iD3L25XglfsaLohSN2h045lHcc+I4dpmu2TGxhz7F7\n1vdzebWoCuUkNHycCl9fIuJM4GLglH6eN5QkqWT+S26QGmkFw23bslU6iy3ksnp1NkAEsNtuPUnf\nu9+zjeYZz7DPtBx7TM6xbY8cz2zOEr7fb8qxvDNHx2Md5B7I8fzW53udLwgmjZ/E1D2n0jyhmRn7\nzOCY6ccULaUw6KLoGlpVLCeh4eNU+IpbD2wDmvu0NwO5gXaMiPcDXwPel1L66WBOtmjRIpqamnq1\ntba20tqJypCfAAAgAElEQVTaOuiAJUm1r62tjba2tl5tGzduHPT+JoQNatu2rAh7seLsq1dnq3tC\nYvSezzHt4BwtMzs44OQcb2jOMaYpx7ZxHbxIjo5NOX7RmeO2Tc+Qnk1QsAbLPuP26TU9c07znKLT\nNSdPmDy0RdE1tKpcTkLDx6nwlZVS6oqIB4DjgR/Aq88EHg98ub/9IqIV+DpwRkrp9sGeb/Hixcyd\nO3fXgpYk1bxiX/YtX76cefPmDWp//xU+gm3f3jvpe+IJWPl44rEnX+TJZzroGpuDiTlG7ZWjaVoH\nE6bnGHNojuY9cmwZ3cHGVzro2t7FU8BT+WNOeHkCLVtaaBmdJXSz951VdLpm84TmyhdF19CznMSI\n5lT4qrgGuCGfGHaXnRgP3AAQEVcC+6eUFua3z8x/9kng/ojoHl3cklLqXetGkqQymBDWue3b4Xe/\ng4cf3cKDj3fwv0/leCLXwW+fy7FuS45t43IwsQMm5hizd47th+XYPndLr2OMGT2WPXtNz5xbdLpm\nTRdF19CynERDaKSp8LUipXRzREwCPks2VXQFcEJK6Zl8lxZgesEuHyVbiOYr+Ve3G8lKVUiStEtM\nCGtY17Yu1m1ax9oXO/j1b3I8vCbH42tz/Oa5Djo6czz/So4to3KkCR0wLj9PeDwwA+LAUew5agqT\n9mjhNU0tHDj5IKbuedwO0zVbJraw97i9XXxFPSwnIQ2rlNK1wLX9fHZ2n+23VyQoSVLDMiGssO1p\nO89ufnaHsglrX8zx5DNZspd7McdzXTm2RJFF5Dbvx24vtbBntPCaPafxmr3ezIFTWjh4Wgt/8Lpm\npu+TJXsNURRdQ8tyEpIkSQ3HhHAIpJTY+NLGLMHrHLgo+rpN63Yoij6qay/Siy2kF5uhswU6D2Hv\nMS0csFczB05q4aBpLRw2o4XDD5rMQbPGsruP5mmoWU5CkiSpIfkvvhKsem4VNz10U5bcbcr1SgBf\n2vZSr75jR41jr2hhbFcLdLbw0vojeWFtM9ueb8knfS3s39TM6/dv5uCZ418tzD57dlbKwaRPFWE5\nCUmSpIZmQliCXGeO6x+8PnvubrdmJm9/I1PSO3j9Sy28uLaZ9Wta+P3KFjava+Hll/ZkPcH06T0F\n2Wef0DvpGzeu2r+RGprlJCRJkhqeCWEJRv9+Ps3ffpqVj8OLL/a0T5uWJXlvn5Ulfd0J4IwZsMce\n1YtX6pflJCRJkoQJYUn22w/mzoUzzuDVKZ4zZ8L48dWOTBoky0lIkiSpgAlhCWbPzv79LNUly0lI\nkiSpj1HVDkDSMOvqgksugWOPzUYDV6zIpouaDEqSJDU8RwilkcxyEpIkSRqAI4TSSJQSLFkCc+bA\nhg1ZOYmLLzYZlCRJUi8mhNJIk8vBySfD+efDwoXw4IPWFpQkSVJRJoTSSHLLLXDooXD//Vk5ia9+\ntWFqC3Z0ZI9JzpyZva9bV+2IJEmSap8JoTQSdHZmC8WcdhrMnw8PP9xwtQVPPx3uvhtWr87eFyyo\ndkSSJEm1zweKpHpnOQkA1q4deFuSJEk7coRQqleWk+hl6tSBtyVJkrQjRwilemQ5iR20t2fTRNeu\nzZLB9vZqRyRJklT7yhohjIhPRMSTEbElIu6NiLfspP/YiLgiItZExNaIWB0RHy4rYqmRWU6iX1Om\nwF13wapV2fuUKdWOSJIkqfaV/K/IiDgDuBr4GPALYBFwR0S8PqW0vp/dvgdMBs4GVgFTcbqqVJpc\nLpsSetttcN55cNVVDbOCqCRJkoZHOcMKi4ClKaWbACLiPOAk4Bzgi307R8QfAW8FZqSUNuSbf1Ne\nuFKDuuWWLBkcNSorJ9FgK4hKkiRpeJQ0ShcRuwHzgJ90t6WUEnAncHQ/u50M/BL4dEQ8HRGPRcTf\nR8S4MmOWGoflJCRJkjSMSh0hnASMBjr6tHcAB/WzzwyyEcKtwGn5Y3wV2Bc4t8TzS43DchKSJEka\nZpV4jm8UsB04M6X0y5TS7cCFwMKI2L0C55fqi+UkJEmSVCGljhCuB7YBzX3am4FcP/usBX6XUuos\naHsECGAa2SIzRS1atIimpqZeba2trbS2tpYYtlQnCstJXHop/M3fuIKoGkJbWxttbW292jZu3Fil\naCRJahwl/UszpdQVEQ8AxwM/AIiIyG9/uZ/d7gbeFxHjU0qb820HkY0aPj3Q+RYvXszcuXNLCVGq\nTynB0qVw4YUwbVpWTuKII6odlVQxxb7sW758OfPmzatSRJIkNYZypoxeA3w0Ij4UEQcDS4DxwA0A\nEXFlRNxY0P87wLPANyPikIg4jmw10utTSi/tUvTSSJDLwcknw/nnw8KF8OCDJoOSJEmqiJLnoqWU\nbo6IScBnyaaKrgBOSCk9k+/SAkwv6L8pIt4J/ANwP1ly+M/AxbsYu1T/LCchSZKkKirr4aSU0rXA\ntf18dnaRtpXACeWcSxqROjvhggvg+uvh1FOzVUQnT652VJIkSWowrlYhVZrlJCRJklQjKlF2QhJY\nTkKSJEk1xxFCqRIKy0lcdhlcdJHlJCRJklR1jhBKwyklWLIE5syBDRuychIXX2wyKEmSpJpgQigN\nF8tJSJIkqcY5TCENB8tJSJIkqQ44QigNpc7OLBE87TSYPx8efthkUJIkSTXLEUJpqFhOQpIkSXXG\nEUJpV1lOQpIkSXXKEUJpV1hOQpIkSXXMEUKpHMNYTqKjIxtsnDkze1+3bgjilSRJkoowIZRKNczl\nJE4/He6+G1avzt4XLBiyQ0uSJEm9OLdNKkUFykmsXTvwtiRJkjRUHCGUBqOC5SSmTh14W5IkSRoq\njhBKO1PhchLt7dk00bVrs2SwvX3YTiVJkqQGZ0Io9aerCy6/HK64IntG8PbbYdasYT/tlClw113D\nfhpJkiTJhFAqynISkiRJagA+QygVGsZyEpIEEBGfiIgnI2JLRNwbEW/ZSf+3RcQDEbE1IlZGxMJK\nxSpJGvlMCKVuw1xOQpIi4gzgauBS4HDgIeCOiJjUT/8DgFuBnwCHAV8Cvh4R76xEvJKkkc+EUIKs\nnMShh8L992flJL76VZgwodpRSRp5FgFLU0o3pZQeBc4DNgPn9NP/fGB1SumvUkqPpZS+Anw/fxxJ\nknaZCaEaWwXLSUhqbBGxGzCPbLQPgJRSAu4Eju5nt6Pynxe6Y4D+kqQK6OiAY4+FmTOz93Xrqh1R\n+XwwSo2rwuUkJDW8ScBooKNPewdwUD/7tPTTf6+I2D2l9FK/Z3vkkTLDlCTtzEXnwOaHoAnYvBr+\n+l3wjW9UO6oCJdwDTAjVeKpUTkKSKmnRWWfR1KetNf+SJO2aHXK/h8jmgFRBW/5VaGMJ+5sQqrFY\nTkJS9awHtgHNfdqbgVw/++T66f/CgKODwOJvfYu5hxxSTpySGsyzz8KnPgXr18OkSXDVVbDvvtWO\nqradcw6seKhne85h1RshLPZl3/JHHmHeWWcNan//JazGkBIsXQoXXgjTpmXlJFxBVFIFpZS6IuIB\n4HjgBwAREfntL/ez2zLgxD5t78q3D+yQQ2Du3LLjldQ4Tj0W7u5Obn4HKy+Du+6qZkS17/M/hgUL\nYO1amDoVPt8OTKl2VOUxIdTIl8tlC8fcdhucd172tZcriEqqjmuAG/KJ4S/IVgsdD9wAEBFXAvun\nlLprDS4BPhERXyCboXQ88D7g3RWOW9IItnbtwNva0ZQpIydpNiHUyHbLLVkyOGpUVk7CFUQlVVFK\n6eZ8zcHPkk39XAGckFJ6Jt+lBZhe0H9NRJwELAY+CTwNnJtS6rvyqCSVbepUWL2697YahwmhRqbO\nTrjgArj+ejj11GwV0cmTqx2VJJFSuha4tp/Pzi7S9jOqtlSBpEbQ3t57+mN7e7UjUiWZEGrksZyE\nJEnSoI2k6Y8qnYXpNXJ0dcEll2TVQSdPhhUrsumiJoOSJElSUY4QamSwnIQkSZJUMkcIVd9SgiVL\nYM4c2LAhKydx8cUmg5IkSdIgmBCqfuVycPLJcP75sHAhPPigtQUlSZKkEjiMovpkOQlJkiRplzlC\nqPrS2ZklgqedBvPnw8MPmwxKkiRJZXKEUPXDchKSJEnSkHKEULXPchKSJEnSsDAhVG1buTKbGvq5\nz2XlJH7+c5g1q9pRSZKkGtTRkX1/PHNm9r5uXbUjkmqfCaFqk+UkJElSiU4/He6+G1avzt4XLKh2\nRPXBRLqxmRCq9lhOQpIklWHt2oG3VZyJdGNzuEW1xXISkiSpTFOnZklN4bZ2zkS6sTlCqNpgOQlJ\nkrSL2tuzf0bMmJG9t7dXO6L60DdxNpHeuZE0zdYRQlWf5SQkSdIQmDIF7rqr2lHUn/b2bJro2rVZ\nMmgivXPd02whG5VesKB+/+yZEKp6urrg8svhiiuyZwRvv90VRCVJkirMRLp0I2mabVlTRiPiExHx\nZERsiYh7I+Itg9xvfkR0RcTycs6rEcRyEpIkSapTI2mabckJYUScAVwNXAocDjwE3BERk3ayXxNw\nI3BnGXFqpLCchCRJkurcSHpetZx/hS8ClqaUbgKIiPOAk4BzgC8OsN8S4NvAduDUMs6repfLZQvH\n3HYbnHceXHUVTJhQ7agkSZKkkoykabYljRBGxG7APOAn3W0ppUQ26nf0APudDRwIfKa8MFX3brkF\nDj0U7r8/Kyfx1a+aDEqSJElVVuqU0UnAaKCjT3sH0FJsh4iYDXwO+EBKaXvJEaq+dXbCRz9qOQlJ\nkiSpBg3rg1sRMYpsmuilKaVV3c2D3X/RokU0NTX1amttbaW1tXXogtTwsZyEpEFqa2ujra2tV9vG\njRurFI0kSQPr6MhKTxSW6pgypdpRlafUhHA9sA1o7tPeDOSK9N8TeDMwJyK+km8bBUREvAy8K6X0\nX/2dbPHixcydO7fEEFV1lpOQVKJiX/YtX76cefPmVSkiSZL6N5LqEJY0ZTSl1AU8ABzf3RYRkd++\np8guLwBvBOYAh+VfS4BH8z/fV1bUql2Wk5AkSdIIN5LqEJYzZfQa4IaIeAD4Bdmqo+OBGwAi4kpg\n/5TSwvyCM78u3Dki1gFbU0qP7ErgqjEpwdKlcOGFMG1aVk7iiCOqHZUkSZI05KZOzUYGC7frVckJ\nYUrp5nzNwc+STRVdAZyQUnom36UFmD50IarmWU5CkiRJDaS9PZsmWvgMYb0qa1GZlNK1wLX9fHb2\nTvb9DJafGDluuSVLBkeNyspJuIKoJEmSRriGrUMovaqzM0sELSchSZIk1a1hLTuhEcpyEpIkSdKI\n4AihBq+rCy65BI49FiZPhhUrslFCk0FJkiSpLjlCqMFZuRLOOguWL8/KSVx0EYzxj48kSZJUzxwh\n1MBSgiVLYM4c2LAhKydx8cUmg5IkSdIIYEKo/nV0wMknw/nnw8KF8OCD1haUJEmSRhCHeVSc5SQk\nSZKkEc8RQvVWWE7imGPgV78yGZQkSZJGKEcI1cNyEpIkSVJDcYRQlpOQJEmSStDRkf3TeebM7H3d\numpHVD5HCBud5SQkSZKkkpx+Otx9d/bz6tWwYAHcdVd1YyqXI4SNynISkiRJYmSNdlXK2rUDb9cT\nE8JGZDkJSZIk5XWPdq1enb0vWFDtiGrf1KkDb9cTh4MajeUkJEmSVGAkjXZVSnt7ljivXZslg+3t\n1Y6ofCaEjaKzEy64AK6/Hk45JVtFdMqUakclSZKkKps6NRsdLNzWwKZMqd9nBvsyIWwElpOQJElS\nP0bSaJdK5zOEI5nlJCSpZkTEPhHx7YjYGBHPR8TXI2LCAP3HRMQXIuJ/IqIzIn4XETdGhN/dSxpS\n3aNdq1Zl704iaywmhCPVypUwfz587nNw6aXw85/DrFnVjkqSGtl3gEOA44GTgOOApQP0Hw/MAT4D\nHA68FzgIuGV4w5QkNRKnjI40KcHSpXDhhTBtWlZOwhVEJamqIuJg4ARgXkrpwXzbnwG3RcRfppRy\nffdJKb2Q36fwOH8K3BcR01JKT1cgdEnSCOcI4UhiOQlJqlVHA893J4N5dwIJOLKE4+yd32fDEMYm\nSWpgjhCOFJaTkKRa1gL0KvWcUtoWEc/lP9upiNgd+DzwnZRS59CHKElqRCaE9c5yEpJUNRFxJfDp\nAboksucGd/U8Y4Dv5Y/38cHss2jRIpqamnq1tba20trauqvhSJJqSFtbG21tbb3aNm7cOOj9TQjr\nmeUkJKnargK+uZM+q4Ec0OvbuogYDeyb/6xfBcngdOD/G+zo4OLFi5k7d+5gukqS6lixL/uWL1/O\nvHnzBrW/CWE96uqCyy+HK67InhG8/XZXEJWkKkgpPQs8u7N+EbEM2DsiDi94jvB4IID7BtivOxmc\nAbw9pfT8rkctSVIPF5WpN5aTkKS6k1J6FLgDuC4i3hIR84F/ANoKVxiNiEcj4tT8z2OAfwHmAmcB\nu0VEc/61W+V/C0nSSOQIYb2wnIQk1bszgX8kW110O/B94M/79JkNdD/49xrgPfmfV+Tfg+w5wrcD\nPxvOYCVJjcGEsB50dGTPB952G5x3Hlx1FUyYUO2oJEklSCltIBvpG6jP6IKfnwJGD9BdkqRdZkJY\n6ywnIUmSJGmY+AxhrerszBLB006DY46BX/3KZFCSJEnSkHKEsBZZTkKSJElSBThCWEu6uuCSS+DY\nY2HyZFixIhslNBmUJEmSNAwcIawVK1fCWWfB8uVZOYm/+RsY438eSZIkScPHEcJqSwmWLIHDD4cN\nG7JyEpdcYjIoSZIkadiZEFZTRwecfDKcfz586EPw4IPWFpQkSZJUMQ5DVUthOYkf/hDe856d7yNJ\nkiRJQ8gRwkorVk7CZFCSJElSFThCWEmWk5AkSZJUQxwhrATLSUiSJEmqQY4QDjfLSUiSJEmqUY4Q\nDhfLSUiSJEmqcSaEw8FyEpIkSZLqgMNVQ81yEpIkSZLqhCOEQ6WzEz76UctJSJIkSaobZSWEEfGJ\niHgyIrZExL0R8ZYB+r43In4cEesiYmNE3BMR7yo/5Bq0bBnMmQNtbVk5iX/7N5gypdpRSZIkSdKA\nSk4II+IM4GrgUuBw4CHgjoiY1M8uxwE/Bk4E5gI/BX4YEYeVFXEtKSwnMWmS5SQkSZIk1ZVyRggX\nAUtTSjellB4FzgM2A+cU65xSWpRSuiql9EBKaVVK6W+Bx4GTy466FqxcCfPnw+c+l5WTuOsumDWr\n2lFJkiRJ0qCVlBBGxG7APOAn3W0ppQTcCRw9yGMEsCfwXCnnrhmWk5AkSZIaWkdHNklw5szsfd26\nakdUvlJHCCcBo4GOPu0dQMsgj/EpYAJwc4nnrj7LSUiSJEkN7/TT4e67YfXq7H3BgmpHVL6KDmtF\nxJnAxcApKaX1O+u/aNEimpqaerW1trbS2to6TBHuxJNPZkmg5SQkaUi1tbXR1tbWq23jxo1VikaS\npIGtXTvwdj0pNSFcD2wDmvu0NwO5gXaMiPcDXwPel1L66WBOtnjxYubOnVtiiMPoqKOyrwF2373a\nkUjSiFLsy77ly5czb968KkUkSVL/pk7N0oLC7XpV0pTRlFIX8ABwfHdb/pnA44F7+tsvIlqB64H3\np5RuLy/UGmEyKEmSJDW09vZsfckZM7L39vZqR1S+cqaMXgPcEBEPAL8gW3V0PHADQERcCeyfUlqY\n3z4z/9kngfsjont0cUtK6YVdil6SJEmSKmzKlKzIwEhQckKYUro5X3Pws2RTRVcAJ6SUnsl3aQGm\nF+zyUbKFaL6Sf3W7kX5KVUiSJEmShl9Zi8qklK4Fru3ns7P7bL+9nHNIkiRJkoZXOYXpJUmSJEkj\ngAmhJEmSJDUoE0JJkiRJalAmhJIkSZLUoEwIJUmSJKlBmRBKkiRJUoMyIZQkSZKkBmVCKEmSJEkN\nyoRQkiRJkhqUCaEkSZIkNSgTQkmSJElqUCaEkiRJktSgTAglSZIkqUGZEEqSJElSgzIhlCRJkqQG\nZUIoSZIkSQ3KhFCSpAqIiH0i4tsRsTEino+Ir0fEhBL2XxIR2yPik8MZpySpsZgQSpJUGd8BDgGO\nB04CjgOWDmbHiHgvcCTwu2GLTpLUkEwIJUkaZhFxMHACcG5K6ZcppXuAPwPeHxEtO9n3NcCXgDOB\nV4Y9WElSQzEhlCRp+B0NPJ9SerCg7U4gkY38FRURAdwEfDGl9MjwhihJakQmhJIkDb8WYF1hQ0pp\nG/Bc/rP+/DXwckrpH4cxNklSAxtT7QAkSapXEXEl8OkBuiSy5wbLOfY84JPA4eXsv2jRIpqamnq1\ntba20traWs7hJEk1qq2tjba2tl5tGzduHPT+JoSSJJXvKuCbO+mzGsgBUwobI2I0sG/+s2KOBSYD\nv81mjgIwGrgmIi5IKc0Y6KSLFy9m7ty5OwlNklTvin3Zt3z5cubNmzeo/U0IJUkqU0rpWeDZnfWL\niGXA3hFxeMFzhMcDAdzXz243Af/Rp+3H+fadJaGSJA2KCaEkScMspfRoRNwBXBcR5wNjgX8A2lJK\nr44QRsSjwKdTSreklJ4Hni88TkR0AbmU0uMVDF+SNIK5qIwkSZVxJvAo2eqitwI/A/5Pnz6zgSb6\nl4YnNElSo3KEUJKkCkgpbQDO2kmf0Tv5fMDnBiVJKpUjhJIkSZLUoEwIJUmSJKlBmRBKkiRJUoMy\nIZQkSZKkBmVCKEmSJEkNyoRQkiRJkhqUCaEkSZIkNSgTQkmSJElqUCaEkiRJktSgTAglSZIkqUGZ\nEEqSJElSgzIhlCRJkqQGZUIoSZIkSQ3KhFCSJEmSGpQJoSRJkiQ1KBPCErW1tVU7hLrkdSud16w8\nXrfSec1UKf5ZK4/XrXRes/J43Uo3Eq5ZWQlhRHwiIp6MiC0RcW9EvGUn/d8WEQ9ExNaIWBkRC8sL\nt/pGwn/0avC6lc5rVh6vW+m8ZqoU/6yVx+tWOq9ZebxupRsJ16zkhDAizgCuBi4FDgceAu6IiEn9\n9D8AuBX4CXAY8CXg6xHxzvJCliRJkiQNhXJGCBcBS1NKN6WUHgXOAzYD5/TT/3xgdUrpr1JKj6WU\nvgJ8P38cSZIkSVKVlJQQRsRuwDyy0T4AUkoJuBM4up/djsp/XuiOAfpLkiRJkipgTIn9JwGjgY4+\n7R3AQf3s09JP/70iYveU0ktF9hkH8Mgjj5QY3vDbuHEjy5cvr3YYdcfrVjqvWXm8bqWr1WtWcA8Y\nV8046pD30BHG61Y6r1l5vG6lq9VrVso9NLIBvsGJiKnA74CjU0r3FbR/ATgupbTDqF9EPAZ8I6X0\nhYK2E8meKxxfLCGMiDOBbw86MEnSSPaBlNJ3qh1EvfAeKkkqsNN7aKkjhOuBbUBzn/ZmINfPPrl+\n+r/Qz+ggZFNKPwCsAbaWGKMkaWQYBxxAdk/Q4HkPlSQN+h5a0gghQETcC9yXUvrz/HYAvwG+nFL6\n+yL9Pw+cmFI6rKDtO8DeKaV3l3RySZIkSdKQKWeV0WuAj0bEhyLiYGAJMB64ASAiroyIGwv6LwFm\nRMQXIuKgiPg48L78cSRJkiRJVVLqlFFSSjfnaw5+lmzq5wrghJTSM/kuLcD0gv5rIuIkYDHwSeBp\n4NyUUt+VRyVJkiRJFVTylFFJkiRJ0shQzpRRSZIkSdIIYEIoSZIkSQ3KhLCPiPhERDwZEVsi4t6I\neMsAfd8bET+OiHURsTEi7omId1Uy3lpRynXrs9/8iOiKiNqr6DnMSr1mETE2Iq6IiDURsTUiVkfE\nhysUbs0o47p9ICJWRMSmiPh9RFwfEftWKt5qi4i3RsQPIuJ3EbE9Ik4ZxD5vi4gH8n/OVkbEwkrE\nqvrnPbQ83kNL5z20PN5DS9Mo91ATwgIRcQZwNXApcDjwEHBHfhGdYo4DfgycCMwFfgr8MCIO66f/\niFTGdeverwm4EWi4BYbKvGbfA94OnA28HmgFHhvmUGtKqdctIuaT/Rm7DngD2QrHRwBfq0jAtWEC\n2eJfHwd2+tB4RBwA3Ar8BDgM+BLw9Yh45/CFqJHAe2h5vIeWzntoebyHlqUh7qEuKlMgitdY/C1Z\njcUvDvIYDwPfTSn93fBFWlvKvW4R0QasBLYDp6aU5lYi3lpQ6jWLiD8CvgPMSCltqGiwNaSM6/YX\nwHkppdkFbX8K/FVK6bUVCrtmRMR24LSU0g8G6PMFstqxbypoawOarB2rgXgPLY/30NJ5Dy2P99Bd\nM5LvoY4Q5kXEbsA8sowegJRly3cCRw/yGAHsCTw3HDHWonKvW0ScDRwIfGa4Y6w1ZV6zk4FfAp+O\niKcj4rGI+PuIGDfsAdeIMq/bMmB6RJyYP0Yz8MfAbcMbbV07ih1HHO5gkH8PqjF5Dy2P99DSeQ8t\nj/fQiqnLe2jJdQhHsEnAaKCjT3sHcNAgj/EpsqHlm/9fe/cPIkcZxnH8+xzCQcQUgkQlARXEPwhe\nkU6NRSS2FirxUFPYSLQQK0EkVkos0gVjEcXCIq2VNkaQnChqo6AiAYWIFrGJwZioeSze93BZ5sQd\nsjuzvt8PvHD77s3yvs/t7W/emZ3dKziusZu5bhFxK/AKcG9mXi77AE3p81y7BbgP+B14qD7G68C1\nwFPzGebozFy3zNyIiMeBEzX4rwLeBZ6d50CX3PV013h7RKxm5sUBxqTxM0P7MUNnZ4b2Y4YuxlJm\nqGcIr5CIWAdeAh7JzLNDj2esImIFeAc4lJmnN7sHHNKyWKG8LWg9Mz/LzPeA54EDEbE67NDGKyLu\npLx//2XKNUoPUo6qvzHgsCRNMUP/GzO0NzO0BzO0HZ4h/MdZ4C9gx1T/DuDnf9swIvZTLrB9ODNP\nzmd4ozVr3a4BdgNrEXG09q1Q3i10CdiXmR/Oaaxj0ee59hPwY2aen+j7mrIjsBM43bnV/0ufur0A\nnMrMI/X2VxFxEPgoIl7MzOmjeCq17KrxubEe2dQomKH9mKGzM0P7MUMXYykz1DOEVWb+AXwO7N3s\nq9cz7AU2ttouIh4DjgP76xGnpvSo2zngLmCN8ulLdwPHgG/qz5/MeciD6/lcOwXcGBHbJvpuoxzx\nPH3eVoEAAAGVSURBVDOnoY5Kz7ptA/6c6rtM+aQwj6p3+5iJGlf7ar/UyQztxwydnRnajxm6MMuZ\noZlpqw14FPgNeBK4nXJK/Bfgunr/q8DbE7+/DlwCnqas/jfb9qHnMua6dWx/CPhi6HmMuWaU62p+\nAE4Ad1A+rv1b4NjQcxl53Q4AF+v/6M3APcCnwMbQc1lgza6m7CiuUYL8uXp71xY1uwn4FThM2WE6\nWF/nHhh6LrZxNzN0MXXr2N4MNUPnVTcztJEMHXwAY2v1D/c9cIGymt89cd9bwAcTt09STr9PtzeH\nnseY69axbXNh1qdmlO9Neh84X4PtNWB16HksQd2eAb6sdTtD+U6lG4aexwLrdX8Nsc7XqS1qtody\nJPkC8B3wxNDzsC1HM0PnX7eObc1QM3SedTNDG8hQv4dQkiRJkhrlNYSSJEmS1CgXhJIkSZLUKBeE\nkiRJktQoF4SSJEmS1CgXhJIkSZLUKBeEkiRJktQoF4SSJEmS1CgXhJIkSZLUKBeEkiRJktQoF4SS\nJEmS1CgXhJIkSZLUqL8BTBR4nIoXgF0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb93c399198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_sample = trdata.next_batch(20).todense()\n",
    "x_mask = np.greater(x_sample, 0.1)\n",
    "x_reconstruct = trained_vae.reconstruct(x_sample)\n",
    "x_errors = x_reconstruct - x_sample\n",
    "x_reduceddim = trained_vae.transform(x_sample) # note that this doesn't sample z's, it only returns z_mean\n",
    "x_loss = trained_vae.loss(x_sample, x_reconstruct)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(11, 3.5))\n",
    "xs = np.asarray(x_sample[x_mask]).flatten()\n",
    "ys = np.asarray(x_reconstruct[x_mask]).reshape(-1)\n",
    "ax[0].plot(xs, ys, 'b.')\n",
    "\n",
    "uniqxs = np.unique(xs)\n",
    "uniqys = [np.mean(ys[np.where(xs == x)]) for x in uniqxs]\n",
    "\n",
    "# the coefficient of this polynomial might be worth maximizing as it shows that the model is producing\n",
    "# a good separation between low and high ratings and not just fitting a constant to the mode of ratings\n",
    "poly = np.poly1d(np.polyfit(xs, ys, 1))\n",
    "uniqpoly = np.poly1d(np.polyfit(uniqxs, uniqys, 1)) # polynomial over the averages for each x value\n",
    "print('poly: {}; uniqpoly: {}'.format(str(poly)[2:], str(uniqpoly)[2:]))\n",
    "\n",
    "ax[0].set_title('Reconstructions')\n",
    "ax[0].plot(uniqxs, poly(uniqxs))\n",
    "ax[0].plot(uniqxs, uniqpoly(uniqxs))\n",
    "ax[0].plot(uniqxs, uniqxs)\n",
    "ax[0].set_xlim(0.1, 1.1); ax[0].set_ylim(0, 1)\n",
    "\n",
    "ax[1].set_title('Errors')\n",
    "ax[1].plot(xs, np.asarray(x_errors[x_mask]).reshape(-1), 'b.')\n",
    "ax[1].plot([0.1, 1.1], [0, 0], 'r')\n",
    "ax[1].set_xlim(0.1, 1.1); ax[1].set_ylim(-0.5, 0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "reconstructed = [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "reduceddim = [[ -1.56848691e-03  -1.35207921e-03   6.11824915e-04   1.27835199e-04\n",
      "    6.97646290e-04   6.50115311e-04  -2.29657814e-03   7.02010351e-04\n",
      "   -9.53270122e-04   1.35938637e-04  -9.00799409e-04  -1.92999840e-04\n",
      "   -1.40437484e-03   4.32812958e-04   2.27833167e-04   1.16935000e-04\n",
      "    5.24884090e-05   9.58738849e-04  -1.41735608e-03   1.23075210e-03]]\n",
      "loss = (nan, 1.7702579e-05)\n"
     ]
    }
   ],
   "source": [
    "x_sample = trdata.next_batch(1).todense()\n",
    "x_reconstruct = np.multiply(trained_vae.reconstruct(x_sample), np.greater(x_sample, 0.1))\n",
    "x_reduceddim = trained_vae.transform(x_sample) # note that this doesn't sample z's, it only returns z_mean\n",
    "x_loss = trained_vae.loss(x_sample, x_reconstruct)\n",
    "print('x = {}'.format(x_sample))\n",
    "print('reconstructed = {}'.format(x_reconstruct))\n",
    "print('reduceddim = {}'.format(x_reduceddim))\n",
    "print('loss = {}'.format(x_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [[ 0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2\n",
      "   0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2\n",
      "   0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2\n",
      "   0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2\n",
      "   0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2\n",
      "   0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2\n",
      "   0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2\n",
      "   0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2\n",
      "   0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2\n",
      "   0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2\n",
      "   0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2\n",
      "   0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2\n",
      "   0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2\n",
      "   0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2\n",
      "   0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2\n",
      "   0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2\n",
      "   0.2  0.2  0.2]]\n",
      "reconstructed = [[ 0.97578645  0.97461206  0.73985392  0.8696205   0.88077408  0.98409039\n",
      "   0.94629854  0.9149707   0.44595733  0.91272599  0.98723292  0.83414054\n",
      "   0.87168163  0.9934094   0.97873962  0.98491991  0.8738094   0.97834593\n",
      "   0.97193718  0.96770579  0.71980762  0.98770255  0.89049131  0.90523779\n",
      "   0.96986312  0.96860754  0.95664561  0.9439171   0.60836726  0.98493409\n",
      "   0.53031248  0.19738737  0.99570638  0.76347554  0.98773682  0.95559514\n",
      "   0.80382293  0.98585957  0.95958644  0.99386013  0.8805607   0.97487086\n",
      "   0.99400973  0.98481041  0.8948831   0.84359533  0.96781969  0.83339208\n",
      "   0.81482595  0.50335318  0.81219721  0.94816583  0.5977993   0.37023112\n",
      "   0.46204072  0.98818064  0.76048177  0.61152315  0.98493332  0.97246563\n",
      "   0.98861337  0.97242379  0.78967732  0.74154323  0.89443308  0.81874937\n",
      "   0.98087835  0.82760632  0.54421222  0.33985409  0.57337475  0.39283052\n",
      "   0.47444034  0.98756856  0.47931382  0.18746907  0.80558109  0.17538995\n",
      "   0.82548773  0.98434573  0.96768022  0.98181355  0.99634665  0.98168242\n",
      "   0.18128689  0.56494403  0.98537272  0.79514879  0.27786133  0.97178584\n",
      "   0.64073896  0.80524474  0.76710802  0.59813887  0.18185602  0.98427874\n",
      "   0.77141666  0.93290854  0.57526988  0.79259437  0.79085457  0.99141032\n",
      "   0.97123104  0.90456688  0.19879119  0.98362815  0.98968571  0.94376403\n",
      "   0.6897909   0.78584617  0.98382866  0.58595395  0.66264623  0.98724246\n",
      "   0.59580576  0.79776973  0.97525066  0.60286516  0.47316676  0.98627812\n",
      "   0.39219248  0.39880341  0.5876627   0.91099405  0.86240464  0.70738602\n",
      "   0.47732604  0.85470623  0.8630622   0.63416338  0.94278789  0.98859614\n",
      "   0.917862    0.96772367  0.91590917  0.98929822  0.99601799  0.93340409\n",
      "   0.91369092  0.20111454  0.73093992  0.79803532  0.3673248   0.83588207\n",
      "   0.7605353   0.65056688  0.77260882  0.97456235  0.99578589  0.95878625\n",
      "   0.5628162   0.19272986  0.9719373   0.87138981  0.90205061  0.93553007\n",
      "   0.79980719  0.7209754   0.94241846  0.92542517  0.77800441  0.85394764\n",
      "   0.84225214  0.95943052  0.73323929  0.9793362   0.83485395  0.69031972\n",
      "   0.96663672  0.69195378  0.99078661  0.79981482  0.7884267   0.92038661\n",
      "   0.83911848  0.78280449  0.88478273  0.8912639   0.7507599   0.82208514\n",
      "   0.79101217  0.66562098  0.53250813  0.71029115  0.65803242  0.98759162\n",
      "   0.62346435  0.79696089  0.82103026  0.4344936   0.97080821  0.49855995\n",
      "   0.46535838  0.54589325  0.73803264  0.82034153  0.68656683  0.55084378\n",
      "   0.71129549  0.20250426  0.3567985   0.609514    0.76645529  0.57807541\n",
      "   0.6893304   0.47320023  0.58470869  0.43679988  0.46788806  0.4172447\n",
      "   0.41430262  0.26063991  0.52325523  0.52845782  0.60988301  0.42956662\n",
      "   0.61808157  0.63858086  0.48537135  0.5766204   0.48011985  0.38371196\n",
      "   0.34205362  0.57216841  0.44956684  0.43903115  0.57810915]]\n",
      "reduceddim = [[ 0.09469698  0.05944517  0.03083582 -0.01264528 -0.01655304 -0.04446443\n",
      "   0.03536202 -0.06425677  0.0264277  -0.04793306  0.05995931 -0.00077318\n",
      "   0.07254232 -0.01528761 -0.05400608  0.01173445  0.01164935 -0.04443838\n",
      "   0.05903999 -0.08086472]]\n",
      "loss = (1.7288885, 0.034525335)\n"
     ]
    }
   ],
   "source": [
    "x_sample = np.ones((1, n_items)) * 0.2\n",
    "x_reconstruct = np.multiply(trained_vae.reconstruct(x_sample), np.greater(x_sample, 0.1))\n",
    "x_reduceddim = trained_vae.transform(x_sample)\n",
    "x_loss = trained_vae.loss(x_sample, x_reconstruct)\n",
    "print('x = {}'.format(x_sample))\n",
    "print('reconstructed = {}'.format(x_reconstruct))\n",
    "print('reduceddim = {}'.format(x_reduceddim))\n",
    "print('loss = {}'.format(x_loss)) # this should be very big b/c the input 'x' is very unlikely given its distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.7288885, 0.034525335)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shouldn't change from previous cell (i.e. b/c no additional sampling has occurred)\n",
    "trained_vae.loss(x_sample, x_reconstruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
