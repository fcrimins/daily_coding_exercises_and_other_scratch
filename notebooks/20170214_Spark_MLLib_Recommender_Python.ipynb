{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Building a Movie Recommendation Service with Apache Spark & Flask/Python](https://www.codementor.io/jadianes/building-a-recommender-with-apache-spark-python-example-app-part1-du1083qbw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pyspark import SparkContext, SparkConf\n",
    "conf = SparkConf().setAppName('20170214_Spark_Recommender_Python').setMaster(\"local[2]\")\n",
    "sc = SparkContext(conf=conf)\n",
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the raw ratings data\n",
    "datasets_path = '/home/fred/data'\n",
    "small_ratings_file = os.path.join(datasets_path, 'amazon', 'ratings_Baby.csv')\n",
    "small_ratings_raw_data = sc.textFile(small_ratings_file)\n",
    "# small_ratings_raw_data_header = small_ratings_raw_data.take(1)[0] # ain't no header in my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this method has collisions (e.g. using hash there are 64391 but just taking the last 8 digits there are 64368)\n",
    "def str2int(s):\n",
    "    return abs(hash(s)) % (10 ** 8)\n",
    "\n",
    "# parse the raw data into a new RDD\n",
    "small_ratings_data = (small_ratings_raw_data\n",
    "    #.filter(lambda line: line != small_ratings_raw_data_header)\n",
    "    .map(lambda line: line.split(\",\"))\n",
    "    .map(lambda tokens: (str2int(tokens[0]), str2int(tokens[1]), tokens[2])).cache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(32140752, 92008734, '5.0'),\n",
       " (99567681, 82257884, '5.0'),\n",
       " (15071229, 80643384, '4.0')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for illustrative purposes, take the first few lines of our RDD to see the result\n",
    "small_ratings_data.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split it into train, validation, and test datasets\n",
    "training_RDD, validation_RDD, test_RDD = small_ratings_data.randomSplit([6, 2, 2], seed=0)\n",
    "training_for_predict_RDD = training_RDD.map(lambda x: (x[0], x[1]))\n",
    "validation_for_predict_RDD = validation_RDD.map(lambda x: (x[0], x[1]))\n",
    "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rp/rank (0.3, 18) the training RMSE is 0.4071467269658386 and validation RMSE is 2.1518842574090336\n",
      "For rp/rank (0.3, 22) the training RMSE is 0.40581488045020164 and validation RMSE is 2.1221218722563933\n",
      "For rp/rank (0.6, 18) the training RMSE is 0.7295444804815372 and validation RMSE is 2.1107169701492996\n",
      "For rp/rank (0.6, 22) the training RMSE is 0.7300551267537654 and validation RMSE is 2.075655216948862\n",
      "The best model was trained with rp/rank (0.6, 22)\n"
     ]
    }
   ],
   "source": [
    "# proceed with the training phase\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "seed = 5\n",
    "iterations = 10\n",
    "regularization_parameters = [0.3, 0.6]\n",
    "ranks = [18, 22]\n",
    "tolerance = 0.02\n",
    "\n",
    "def rmse(data_RDD, data_for_predict_RDD):\n",
    "    predictions = model.predictAll(data_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    #predictions.take(3) # [Managed Memory Leak Msg Should Only Be a Warning](https://issues.apache.org/jira/browse/SPARK-14168)\n",
    "    rates_and_preds = data_RDD.map(lambda r: ((r[0], r[1]), float(r[2]))).join(predictions)\n",
    "    #rates_and_preds.take(5)\n",
    "    error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    return (error, rates_and_preds)\n",
    "\n",
    "min_error = float('inf')\n",
    "best = -1\n",
    "for rp, rank in itertools.product(regularization_parameters, ranks):\n",
    "    model = ALS.train(training_RDD,\n",
    "                      rank, # number of latent factors in the model\n",
    "                      seed=seed,\n",
    "                      iterations=iterations,\n",
    "                      lambda_=rp) # lambda_ specifies the regularization parameter in ALS\n",
    "    \n",
    "    terror = rmse(training_RDD, training_for_predict_RDD)[0]\n",
    "    verror = rmse(validation_RDD, validation_for_predict_RDD)[0]\n",
    "    print('For rp/rank {} the training RMSE is {} and validation RMSE is {}'.format((rp, rank), terror, verror))\n",
    "    if verror < min_error:\n",
    "        min_error = verror\n",
    "        best = (rp, rank)\n",
    "\n",
    "print('The best model was trained with rp/rank {}'.format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For testing data the RMSE is 2.0735024116449736\n"
     ]
    }
   ],
   "source": [
    "model = ALS.train(training_RDD, best[1], seed=seed, iterations=iterations, lambda_=best[0])\n",
    "(error, rates_and_preds) = rmse(test_RDD, test_for_predict_RDD)\n",
    "print('For testing data the RMSE is {}'.format(error)) # 2.0735"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((11139009, 52261773), (5.0, 1.2892196214442693)),\n",
       " ((55849902, 14036664), (5.0, 1.226805107805887)),\n",
       " ((94035557, 49751529), (1.0, 2.0351829362849623)),\n",
       " ((83221295, 41831799), (5.0, 3.1790315566727143)),\n",
       " ((77215656, 1873142), (5.0, 3.6003108064750045)),\n",
       " ((86965400, 48183970), (5.0, 3.535596767059843)),\n",
       " ((50675945, 27475733), (5.0, -0.5908317753357553)),\n",
       " ((79618307, 40660303), (4.0, 3.478527167949731)),\n",
       " ((46292038, 25687912), (5.0, 3.0671195044435495)),\n",
       " ((16987148, 18698726), (4.0, 0.8906650441849951))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates_and_preds.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training data the RMSE is 0.7300551267537654\n"
     ]
    }
   ],
   "source": [
    "(terror, rates_and_preds) = rmse(training_RDD, training_for_predict_RDD)\n",
    "print('For training data the RMSE is {}'.format(terror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((56503762, 17061952), (5.0, 4.348035443906253)),\n",
       " ((58026780, 29894974), (5.0, 4.392538989692055)),\n",
       " ((94728161, 32828469), (5.0, 2.8982636681644807)),\n",
       " ((26470646, 49417676), (1.0, 0.8467392719615738)),\n",
       " ((144989, 7223697), (5.0, 4.398401924016896)),\n",
       " ((55306509, 72726565), (5.0, 4.402950752519727)),\n",
       " ((97616838, 96379596), (4.0, 3.5059729346672937)),\n",
       " ((79595097, 29276793), (5.0, 4.098479102578497)),\n",
       " ((9701402, 64975656), (2.0, 1.6877662435124414)),\n",
       " ((2103967, 27619211), (1.0, 0.8360267995153563))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates_and_preds.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"That is, the recommender needs to be trained every time we have new user ratings (although a single model can be used by multiple users of course!).\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Due to its very nature, collaborative filtering is a costly procedure since requires updating its model when new user preferences arrive. Therefore, having a distributed computation engine such as Spark to perform model computation is a must in any real-world recommendation engine like the one we have built here.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
